Container: container_e32_1658913050359_2550751_01_000001 on shky-sc-bigdata-node04_46661
==========================================================================================
LogType:jobmanager.err
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:555
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/filecache/13/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
End of LogType:jobmanager.errLogType:jobmanager.log
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:8335927
Log Contents:
2023-03-24 20:44:23,275 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2023-03-24 20:44:23,279 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting YarnJobClusterEntrypoint (Version: 1.13.3, Scala: 2.11, Rev:a4700e3, Date:2021-10-11T23:52:36+02:00)
2023-03-24 20:44:23,279 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: yarn
2023-03-24 20:44:23,638 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: yarn
2023-03-24 20:44:23,638 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.241-b07
2023-03-24 20:44:23,638 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 433 MiBytes
2023-03-24 20:44:23,639 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /usr/java/jdk1.8.0_241
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Hadoop version: 2.7.5
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx469762048
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms469762048
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2023-03-24 20:44:23,640 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/vdir/mnt/disk9/hadoop/yarn/logs/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/jobmanager.log
2023-03-24 20:44:23,641 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:log4j.properties
2023-03-24 20:44:23,641 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:log4j.properties
2023-03-24 20:44:23,641 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments:
2023-03-24 20:44:23,642 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.off-heap.size=134217728b
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.min=201326592b
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-metaspace.size=268435456b
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.heap.size=469762048b
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.max=201326592b
2023-03-24 20:44:23,643 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: :DCOL-SSHQ-DEAL-RT.jar:lib/flink-connector-debezium-2.1.0.jar:lib/flink-connector-mysql-cdc-2.1.0.jar:lib/flink-csv-1.13.3.jar:lib/flink-json-1.13.3.jar:lib/flink-metrics-prometheus-1.13.3.jar:lib/flink-runtime-web_2.11-1.13.3.jar:lib/flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-table-api-java-1.13.3.jar:lib/flink-table-api-java-bridge_2.11-1.13.3.jar:lib/flink-table-blink_2.11-1.13.3.jar:lib/flink-table-common-1.13.3.jar:lib/flink-table-planner-blink_2.11-1.13.3.jar:lib/flink-table_2.11-1.13.3.jar:lib/hadoop-auth-2.9.2.jar:lib/hadoop-client-2.9.2.jar:lib/hadoop-common-2.9.2.jar:lib/hadoop-hdfs-2.9.2.jar:lib/hudi-flink-bundle_2.11-0.10.0.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-8.0.16.jar:flink-dist_2.11-1.13.3.jar:job.graph:flink-conf.yaml::/etc/yarn1/conf:/usr/lib/hadoop/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/annotations-13.0.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/dnw-1.0.7.jar:/usr/lib/hadoop/lib/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jmxtrans-agent-1.1.1-transwarp.jar:/usr/lib/hadoop/lib/jna-4.2.1.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/netty-all-4.1.5.transwarp.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/sk-0.0.1.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/annotations-13.0.jar:/usr/lib/hadoop-hdfs/lib/apacheds-jdbm1-2.0.0-M2.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/dnw-1.0.7.jar:/usr/lib/hadoop-hdfs/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/hdfs-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop-hdfs/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-api-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-client-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-registry-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/annotations-13.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/avro-1.7.4.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/dom4j-1.6.1.jar:/usr/lib/hadoop-yarn/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/junit-4.11.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/paranamer-2.3.jar:/usr/lib/hadoop-yarn/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2-tests.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/spark-3.1.2-yarn-shuffle.jar:/usr/lib/hadoop-mapreduce/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/activation-1.1.jar:/usr/lib/hadoop-mapreduce/annotations-13.0.jar:/usr/lib/hadoop-mapreduce/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/asm-3.2.jar:/usr/lib/hadoop-mapreduce/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/dnw-1.0.7.jar:/usr/lib/hadoop-mapreduce/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/hadoop-ant-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-archives-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-aws-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-azure-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-datajoin-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-distcp-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-extras-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-gridmix-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-app-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-core-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-openstack-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-rumen-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-sls-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-streaming-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/jettison-1.1.jar:/usr/lib/hadoop-mapreduce/jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/jna-4.2.1.jar:/usr/lib/hadoop-mapreduce/joda-time-2.10.6.jar:/usr/lib/hadoop-mapreduce/jsch-0.1.54.jar:/usr/lib/hadoop-mapreduce/jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/junit-4.11.jar:/usr/lib/hadoop-mapreduce/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-mapreduce/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/sk-0.0.1.jar:/usr/lib/hadoop-mapreduce/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-mapreduce/xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/xz-1.0.jar:/usr/lib/hadoop-mapreduce/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar
2023-03-24 20:44:23,646 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2023-03-24 20:44:23,647 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2023-03-24 20:44:23,650 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - YARN daemon is running as: yarn Yarn client user obtainer: bigdata_dcm_flink@tdhsh
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.jobgraph-path, job.graph
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.port, 9091
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.interval, 30 SECONDS
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.jobName, flink_reporter_promgateway
2023-03-24 20:44:23,663 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1658913050359_2550751
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.contexts, Client,KafkaClient
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.use-ticket-cache, true
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.class, org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 5
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.randomJobNameSuffix, true
2023-03-24 20:44:23,664 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 5
2023-03-24 20:44:23,664 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/flink-conf.yaml:15: "pipeline.classpaths: "
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application.name, DCOL_SSHQ_DEAL_CFETS_RT
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 4096mb
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-per-job
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1024mb
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.principal, bigdata_dcm_flink@tdhsh
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.deleteOnShutdown, false
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, false
2023-03-24 20:44:23,665 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, DETACHED
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/app/dcol/bigdata_app/cbpc-dcol-sshq-rt/cbpc-dcol-sshq-deal-rt/DCOL-SSHQ-DEAL-RT.jar
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.keytab, /app/dcol/keytabs/flink/bigdata_dcm_flink.keytab
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.host, dcol-bigdataservice-node01.cbpc.ccdcpro
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /app/dcol/flink/conf
2023-03-24 20:44:23,666 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /app/dcol/flink/conf/log4j.properties
2023-03-24 20:44:23,690 WARN  org.apache.flink.configuration.Configuration                 [] - Config uses deprecated configuration key 'web.port' instead of proper key 'rest.bind-port'
2023-03-24 20:44:23,701 INFO  org.apache.flink.yarn.Utils                                  [] - Resolved keytab path: /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/krb5.keytab
2023-03-24 20:44:23,704 INFO  org.apache.flink.runtime.clusterframework.BootstrapTools     [] - Setting directories for temporary files to: /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751
2023-03-24 20:44:23,709 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting YarnJobClusterEntrypoint.
2023-03-24 20:44:23,750 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2023-03-24 20:44:23,792 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2023-03-24 20:44:24,179 INFO  org.apache.hadoop.security.UserGroupInformation              [] - Login successful for user bigdata_dcm_flink@tdhsh using keytab file /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/krb5.keytab
2023-03-24 20:44:24,181 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user set to bigdata_dcm_flink@tdhsh (auth:KERBEROS)
2023-03-24 20:44:24,182 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Kerberos security is enabled and credentials are valid.
2023-03-24 20:44:24,189 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/jaas-8935043385968812219.conf.
2023-03-24 20:44:24,215 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2023-03-24 20:44:24,235 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address shky-sc-bigdata-node04:0, bind address 0.0.0.0:0.
2023-03-24 20:44:24,733 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-03-24 20:44:24,756 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-03-24 20:44:24,877 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@shky-sc-bigdata-node04:44279]
2023-03-24 20:44:25,036 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@shky-sc-bigdata-node04:44279
2023-03-24 20:44:25,062 WARN  org.apache.flink.configuration.Configuration                 [] - Config uses deprecated configuration key 'web.port' instead of proper key 'rest.port'
2023-03-24 20:44:25,071 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/blobStore-e36acab6-d398-4627-94bd-7c85827f29de
2023-03-24 20:44:25,074 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 0.0.0.0:40941 - max concurrent requests: 50 - max backlog: 1000
2023-03-24 20:44:25,098 WARN  org.apache.flink.runtime.metrics.ReporterSetup               [] - Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for org.apache.flink.metrics.prometheus.PrometheusReporterFactory. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.
2023-03-24 20:44:25,098 WARN  org.apache.flink.runtime.metrics.ReporterSetup               [] - Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.
2023-03-24 20:44:25,103 INFO  org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory [] - Configured PrometheusPushGatewayReporter with {host:dcol-bigdataservice-node01.cbpc.ccdcpro, port:9091, jobName:flink_reporter_promgatewayc0498a206817da21d8b840b6ab595c00, randomJobNameSuffix:true, deleteOnShutdown:false, groupingKey:{}}
2023-03-24 20:44:25,112 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - Periodically reporting metrics in intervals of 30 s for reporter promgateway of type org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.
2023-03-24 20:44:25,116 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address shky-sc-bigdata-node04:0, bind address 0.0.0.0:0.
2023-03-24 20:44:25,131 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-03-24 20:44:25,133 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-03-24 20:44:25,140 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@shky-sc-bigdata-node04:37957]
2023-03-24 20:44:25,185 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@shky-sc-bigdata-node04:37957
2023-03-24 20:44:25,197 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2023-03-24 20:44:25,248 WARN  org.apache.flink.configuration.Configuration                 [] - Config uses deprecated configuration key 'web.port' instead of proper key 'rest.bind-port'
2023-03-24 20:44:25,251 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Upload directory /tmp/flink-web-152c22e1-ebc7-402b-a3c0-34a5b9273d03/flink-web-upload does not exist. 
2023-03-24 20:44:25,251 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Created directory /tmp/flink-web-152c22e1-ebc7-402b-a3c0-34a5b9273d03/flink-web-upload for file uploads.
2023-03-24 20:44:25,268 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Starting rest endpoint.
2023-03-24 20:44:25,577 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /vdir/mnt/disk9/hadoop/yarn/logs/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/jobmanager.log
2023-03-24 20:44:25,577 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /vdir/mnt/disk9/hadoop/yarn/logs/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/jobmanager.out
2023-03-24 20:44:25,723 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Rest endpoint listening at shky-sc-bigdata-node04:42840
2023-03-24 20:44:25,724 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - http://shky-sc-bigdata-node04:42840 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2023-03-24 20:44:25,725 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Web frontend listening at http://shky-sc-bigdata-node04:42840.
2023-03-24 20:44:25,767 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.jobgraph-path, job.graph
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.port, 9091
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.interval, 30 SECONDS
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.jobName, flink_reporter_promgateway
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1658913050359_2550751
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.contexts, Client,KafkaClient
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.use-ticket-cache, true
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.class, org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 5
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.randomJobNameSuffix, true
2023-03-24 20:44:25,768 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 5
2023-03-24 20:44:25,768 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/flink-conf.yaml:15: "pipeline.classpaths: "
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application.name, DCOL_SSHQ_DEAL_CFETS_RT
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 4096mb
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-per-job
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1024mb
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.principal, bigdata_dcm_flink@tdhsh
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.deleteOnShutdown, false
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, false
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, DETACHED
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/app/dcol/bigdata_app/cbpc-dcol-sshq-rt/cbpc-dcol-sshq-deal-rt/DCOL-SSHQ-DEAL-RT.jar
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.keytab, /app/dcol/keytabs/flink/bigdata_dcm_flink.keytab
2023-03-24 20:44:25,769 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.host, dcol-bigdataservice-node01.cbpc.ccdcpro
2023-03-24 20:44:25,770 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /app/dcol/flink/conf
2023-03-24 20:44:25,770 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /app/dcol/flink/conf/log4j.properties
2023-03-24 20:44:25,836 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager at akka://flink/user/rpc/resourcemanager_0 .
2023-03-24 20:44:25,916 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2023-03-24 20:44:25,921 INFO  org.apache.flink.runtime.dispatcher.runner.JobDispatcherLeaderProcess [] - Start JobDispatcherLeaderProcess.
2023-03-24 20:44:25,927 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.MiniDispatcher at akka://flink/user/rpc/dispatcher_1 .
2023-03-24 20:44:25,936 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Starting the resource manager.
2023-03-24 20:44:25,968 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_2 .
2023-03-24 20:44:25,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87).
2023-03-24 20:44:26,009 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy FixedDelayRestartBackoffTimeStrategy(maxNumberRestartAttempts=2147483647, backoffTimeMS=1000) for DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87).
2023-03-24 20:44:26,053 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87).
2023-03-24 20:44:26,053 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2023-03-24 20:44:26,072 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 5 pipelined regions in 3 ms
2023-03-24 20:44:26,079 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-24 20:44:26,090 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:26,091 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:26,092 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:26,126 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Recovered 0 containers from previous attempts ([]).
2023-03-24 20:44:26,126 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Recovered 0 workers from previous attempt.
2023-03-24 20:44:26,128 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2023-03-24 20:44:26,133 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Upper bound of the thread pool size is 500
2023-03-24 20:44:26,135 INFO  org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy [] - yarn.client.max-cached-nodemanagers-proxies : 0
2023-03-24 20:44:26,138 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - ResourceManager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/resourcemanager_0 was granted leadership with fencing token 00000000000000000000000000000000
2023-03-24 20:44:26,280 WARN  org.apache.hadoop.fs.FileSystem                              [] - Cannot load: org.apache.hadoop.fs.sftp.SFTPFileSystem@43bde3aa from /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/filecache/32/hadoop-common-2.9.2.jar
java.lang.UnsupportedOperationException: Not implemented by the SFTPFileSystem FileSystem implementation
	at org.apache.hadoop.fs.FileSystem.getScheme(FileSystem.java:218) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:2631) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2648) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:98) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:526) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:407) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.Path.getFileSystem(Path.java:274) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.state.filesystem.FsCheckpointStorageAccess.<init>(FsCheckpointStorageAccess.java:64) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.state.filesystem.FsStateBackend.createCheckpointStorage(FsStateBackend.java:527) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.<init>(CheckpointCoordinator.java:322) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.checkpoint.CheckpointCoordinator.<init>(CheckpointCoordinator.java:241) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraph.enableCheckpointing(DefaultExecutionGraph.java:448) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.executiongraph.DefaultExecutionGraphBuilder.buildGraph(DefaultExecutionGraphBuilder.java:311) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.scheduler.DefaultExecutionGraphFactory.createAndRestoreExecutionGraph(DefaultExecutionGraphFactory.java:107) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.scheduler.SchedulerBase.createAndRestoreExecutionGraph(SchedulerBase.java:342) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.scheduler.SchedulerBase.<init>(SchedulerBase.java:190) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.<init>(DefaultScheduler.java:122) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.scheduler.DefaultSchedulerFactory.createInstance(DefaultSchedulerFactory.java:132) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.DefaultSlotPoolServiceSchedulerFactory.createScheduler(DefaultSlotPoolServiceSchedulerFactory.java:110) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.JobMaster.createScheduler(JobMaster.java:340) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.JobMaster.<init>(JobMaster.java:317) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.internalCreateJobMasterService(DefaultJobMasterServiceFactory.java:107) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.factories.DefaultJobMasterServiceFactory.lambda$createJobMasterService$0(DefaultJobMasterServiceFactory.java:95) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.util.function.FunctionUtils.lambda$uncheckedSupplier$4(FunctionUtils.java:112) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1604) [?:1.8.0_241]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-24 20:44:26,560 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-03-24 20:44:26,573 WARN  org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory      [] - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
2023-03-24 20:44:26,652 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2023-03-24 20:44:26,659 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@184c0b8c for DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87).
2023-03-24 20:44:26,671 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87) under job master id 00000000000000000000000000000000.
2023-03-24 20:44:26,673 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2023-03-24 20:44:26,673 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87) switched from state CREATED to RUNNING.
2023-03-24 20:44:26,682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,701 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,702 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,703 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,703 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from CREATED to SCHEDULED.
2023-03-24 20:44:26,704 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2023-03-24 20:44:26,709 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2023-03-24 20:44:26,712 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/jobmanager_2 for job 774f830cc122ae677f260abe1f050e87.
2023-03-24 20:44:26,717 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/jobmanager_2 for job 774f830cc122ae677f260abe1f050e87.
2023-03-24 20:44:26,720 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2023-03-24 20:44:26,722 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job 774f830cc122ae677f260abe1f050e87: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=5}]
2023-03-24 20:44:26,730 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requesting new worker with resource spec WorkerResourceSpec {cpuCores=5.0, taskHeapSize=1.425gb (1530082070 bytes), taskOffHeapSize=0 bytes, networkMemSize=343.040mb (359703515 bytes), managedMemSize=1.340gb (1438814063 bytes), numSlots=5}, current pending count: 1.
2023-03-24 20:44:26,739 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Requesting new TaskExecutor container with resource TaskExecutorProcessSpec {cpuCores=5.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=1.425gb (1530082070 bytes), taskOffHeapSize=0 bytes, networkMemSize=343.040mb (359703515 bytes), managedMemorySize=1.340gb (1438814063 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=409.600mb (429496736 bytes), numSlots=5}, priority 1.
2023-03-24 20:44:31,694 INFO  org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl        [] - Received new token for : shky-sc-bigdata-node04:46661
2023-03-24 20:44:31,698 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 1 containers.
2023-03-24 20:44:31,699 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Received 1 containers with priority 1, 1 pending container requests.
2023-03-24 20:44:31,715 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Removing container request Capability[<memory:4096, vCores:5>]Priority[1].
2023-03-24 20:44:31,715 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Accepted 1 requested containers, returned 0 excess containers, 0 pending container requests of resource <memory:4096, vCores:5>.
2023-03-24 20:44:31,715 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - TaskExecutor container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661) will be started on shky-sc-bigdata-node04 with TaskExecutorProcessSpec {cpuCores=5.0, frameworkHeapSize=128.000mb (134217728 bytes), frameworkOffHeapSize=128.000mb (134217728 bytes), taskHeapSize=1.425gb (1530082070 bytes), taskOffHeapSize=0 bytes, networkMemSize=343.040mb (359703515 bytes), managedMemorySize=1.340gb (1438814063 bytes), jvmMetaspaceSize=256.000mb (268435456 bytes), jvmOverheadSize=409.600mb (429496736 bytes), numSlots=5}.
2023-03-24 20:44:31,718 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Adding keytab hdfs://nameservice1/user/bigdata_dcm_flink/.flink/application_1658913050359_2550751/bigdata_dcm_flink.keytab to the AM container local resource bucket
2023-03-24 20:44:31,754 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Creating container launch context for TaskManagers
2023-03-24 20:44:31,757 INFO  org.apache.flink.yarn.YarnResourceManagerDriver              [] - Starting TaskManagers
2023-03-24 20:44:31,773 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Requested worker container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661) with resource spec WorkerResourceSpec {cpuCores=5.0, taskHeapSize=1.425gb (1530082070 bytes), taskOffHeapSize=0 bytes, networkMemSize=343.040mb (359703515 bytes), managedMemSize=1.340gb (1438814063 bytes), numSlots=5}.
2023-03-24 20:44:31,773 INFO  org.apache.hadoop.yarn.client.api.async.impl.NMClientAsyncImpl [] - Processing Event EventType: START_CONTAINER for Container container_e32_1658913050359_2550751_01_000002
2023-03-24 20:44:31,774 INFO  org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy [] - Opening proxy : shky-sc-bigdata-node04:46661
2023-03-24 20:44:35,680 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Registering TaskManager with ResourceID container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661) (akka.tcp://flink@shky-sc-bigdata-node04:41438/user/rpc/taskmanager_0) at ResourceManager
2023-03-24 20:44:35,707 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661) is registered.
2023-03-24 20:44:35,707 INFO  org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Worker container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661) with resource spec WorkerResourceSpec {cpuCores=5.0, taskHeapSize=1.425gb (1530082070 bytes), taskOffHeapSize=0 bytes, networkMemSize=343.040mb (359703515 bytes), managedMemSize=1.340gb (1438814063 bytes), numSlots=5} was requested in current attempt. Current pending count after registering: 0.
2023-03-24 20:44:35,760 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,761 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Custom Source -> Filter -> Map -> Filter (1/5) (attempt #0) with attempt id 4d6da1600770b90d8f60defe4d0311ba to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 93bc4f3c9b477e3134dc0d67859df528
2023-03-24 20:44:35,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,765 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (attempt #0) with attempt id 8cf6370b3399f7f43c05f7a877113cdf to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 93bc4f3c9b477e3134dc0d67859df528
2023-03-24 20:44:35,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Custom Source -> Filter -> Map -> Filter (2/5) (attempt #0) with attempt id 978fd1b611d73c411d847dffec70d29c to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 9056be28bacb9f95380bf0b93de5d64d
2023-03-24 20:44:35,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,766 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (attempt #0) with attempt id 2115d8c6b643423bd305f5144d07587c to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 9056be28bacb9f95380bf0b93de5d64d
2023-03-24 20:44:35,767 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,767 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Custom Source -> Filter -> Map -> Filter (3/5) (attempt #0) with attempt id c90825f4e738add5ab63f914f2e6a4ae to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 8025777fbe2631885fb5d9466fd5dfa9
2023-03-24 20:44:35,767 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,767 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (attempt #0) with attempt id 007396f72e57ed39c1719cd34b8356fc to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 8025777fbe2631885fb5d9466fd5dfa9
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Custom Source -> Filter -> Map -> Filter (4/5) (attempt #0) with attempt id f4d32841b96f5f787d00d231f35273b2 to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 04ab40255d0aba821d9d02ce47254eb3
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (attempt #0) with attempt id f2dfb07068016004d30684789db0df2a to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 04ab40255d0aba821d9d02ce47254eb3
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Custom Source -> Filter -> Map -> Filter (5/5) (attempt #0) with attempt id c1b649d3db941e69e5c2278485ae5272 to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 699c89c4ed3f2849f0818b32e1f9bdc0
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from SCHEDULED to DEPLOYING.
2023-03-24 20:44:35,768 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (attempt #0) with attempt id db9fbbfeccb06651ea8b1354240a2008 to container_e32_1658913050359_2550751_01_000002 @ shky-sc-bigdata-node04 (dataPort=35157) with allocation id 699c89c4ed3f2849f0818b32e1f9bdc0
2023-03-24 20:44:36,428 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:37,204 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,204 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,205 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,206 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,206 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,257 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,268 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,277 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,287 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,312 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from INITIALIZING to RUNNING.java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-25 04:33:23,703 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:35004] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:33:49,678 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:37070] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:34:00,672 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 80
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-25 04:35:25,785 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:51434] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:35:32,290 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:51158] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:35:35,756 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 71
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-25 04:38:18,386 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:44400] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:38:24,894 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:44146] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:38:28,402 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 80
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-25 04:39:06,535 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:50490] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:39:06,939 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:49440] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:39:06,939 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 71
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:698) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:698) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-26 04:33:03,358 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:46292] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:33:28,884 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:48136] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:33:39,895 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 80
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-26 04:34:34,968 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:58096] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:34:41,955 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:57950] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:34:44,975 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 71
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-26 04:38:15,665 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:57548] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:38:22,643 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:57286] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:38:26,150 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 80
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-26 04:39:19,183 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:36908] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:39:19,190 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:35824] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:39:19,190 ERROR org.apache.flink.runtime.blob.BlobServerConnection           [] - Error while executing BLOB connection.
java.io.IOException: Unknown operation 71
	at org.apache.flink.runtime.blob.BlobServerConnection.run(BlobServerConnection.java:116) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-26 05:22:24,875 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:22:24,889 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:22:24,892 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:22:24,893 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 1 fail over attempts. Trying to fail over after sleeping for 36472ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:23:01,367 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:23:01,369 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:23:01,369 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 2 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:23:01,371 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:23:01,372 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 3 fail over attempts. Trying to fail over after sleeping for 17415ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:23:18,789 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:23:18,790 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:23:18,791 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 4 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:23:18,793 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:23:18,793 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 5 fail over attempts. Trying to fail over after sleeping for 41353ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:24:00,148 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:24:00,150 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:24:00,150 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 6 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:24:00,152 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:24:00,152 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 7 fail over attempts. Trying to fail over after sleeping for 18038ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:24:18,192 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:24:18,193 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:24:18,194 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 8 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:24:18,196 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:24:18,196 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 9 fail over attempts. Trying to fail over after sleeping for 38740ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:24:56,938 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:24:56,939 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:24:56,940 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 10 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:24:56,941 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:24:56,943 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 11 fail over attempts. Trying to fail over after sleeping for 40885ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:25:37,829 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:25:37,831 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:25:37,831 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 12 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:25:37,833 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:25:37,834 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 13 fail over attempts. Trying to fail over after sleeping for 38957ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:26:16,792 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:26:16,794 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:26:16,794 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 14 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:26:16,796 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:26:16,797 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 15 fail over attempts. Trying to fail over after sleeping for 16843ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:26:33,642 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:26:33,643 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:26:33,643 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 16 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:26:33,645 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:26:33,646 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 17 fail over attempts. Trying to fail over after sleeping for 36469ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:27:10,118 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:27:10,119 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:27:10,120 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 18 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:27:10,122 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:27:10,123 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 19 fail over attempts. Trying to fail over after sleeping for 33628ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:27:43,754 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:27:43,756 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:27:43,756 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 20 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:27:43,758 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:27:43,759 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 21 fail over attempts. Trying to fail over after sleeping for 27850ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:28:11,612 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:28:11,614 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:28:11,614 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 22 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:28:11,617 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:28:11,618 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 23 fail over attempts. Trying to fail over after sleeping for 24880ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:28:36,501 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:28:36,503 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:28:36,504 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 24 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:28:36,506 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:28:36,507 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 25 fail over attempts. Trying to fail over after sleeping for 44860ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:29:21,371 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:29:21,373 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:29:21,374 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 26 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:29:21,375 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:29:21,376 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 27 fail over attempts. Trying to fail over after sleeping for 20513ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:29:41,892 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:29:41,896 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:29:41,897 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm2 after 28 fail over attempts. Trying to fail over immediately.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:29:41,901 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm1
2023-03-26 05:29:41,902 INFO  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking allocate of class ApplicationMasterProtocolPBClientImpl over rm1 after 29 fail over attempts. Trying to fail over after sleeping for 23433ms.
java.net.ConnectException: Call From shky-sc-bigdata-node04/25.11.37.4 to shky-sc-bigdata-node01:8030 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor47.newInstance(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1480) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_241]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_241]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:615) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:713) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1452) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 12 more
2023-03-26 05:30:05,339 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider [] - Failing over to rm2
2023-03-26 05:30:05,340 WARN  org.apache.hadoop.ipc.Client                                 [] - Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.token.SecretManager$InvalidToken): Invalid AMRMToken from appattempt_1658913050359_2550751_000001
2023-03-26 05:30:05,343 WARN  org.apache.hadoop.io.retry.RetryInvocationHandler            [] - Exception while invoking class org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate over rm2. Not retrying because failovers (30) exceeded maximum allowed (30)
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) [?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:30:05,345 ERROR org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl [] - Exception on heartbeat
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:30:05,346 INFO  org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl [] - Interrupted while waiting for queue
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[?:1.8.0_241]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2048) ~[?:1.8.0_241]
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$CallbackHandlerThread.run(AMRMClientAsyncImpl.java:287) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
2023-03-26 05:30:05,347 ERROR org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl [] - Stopping callback due to: 
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:30:05,349 ERROR org.apache.flink.runtime.resourcemanager.active.ActiveResourceManager [] - Fatal error occurred in ResourceManager.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:30:05,367 ERROR org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Fatal error occurred in the cluster entrypoint.
org.apache.hadoop.security.token.SecretManager$InvalidToken: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[?:1.8.0_241]
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_241]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_241]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy35.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:277) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.yarn.client.api.async.impl.AMRMClientAsyncImpl$HeartbeatThread.run(AMRMClientAsyncImpl.java:237) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
Caused by: org.apache.hadoop.ipc.RemoteException: Invalid AMRMToken from appattempt_1658913050359_2550751_000001
	at org.apache.hadoop.ipc.Client.call(Client.java:1476) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.Client.call(Client.java:1413) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at com.sun.proxy.$Proxy34.allocate(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	... 8 more
2023-03-26 05:30:05,370 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Shutting YarnJobClusterEntrypoint down with application status UNKNOWN. Diagnostics Cluster entrypoint has been closed externally..
2023-03-26 05:30:05,372 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Shutting down rest endpoint.
2023-03-26 05:30:05,375 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 0.0.0.0:40941
2023-03-26 05:30:05,407 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Removing cache directory /tmp/flink-web-152c22e1-ebc7-402b-a3c0-34a5b9273d03/flink-web-ui
2023-03-26 05:30:05,411 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - http://shky-sc-bigdata-node04:42840 lost leadership
2023-03-26 05:30:05,411 INFO  org.apache.flink.runtime.jobmaster.MiniDispatcherRestEndpoint [] - Shut down complete.
2023-03-26 05:30:05,411 INFO  org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent [] - Closing components.
2023-03-26 05:30:05,412 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was revoked the leadership with leader id 00000000-0000-0000-0000-000000000000. Stopping the DispatcherLeaderProcess.
2023-03-26 05:30:05,412 INFO  org.apache.flink.runtime.dispatcher.runner.JobDispatcherLeaderProcess [] - Stopping JobDispatcherLeaderProcess.
2023-03-26 05:30:05,413 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Stopping dispatcher akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/dispatcher_1.
2023-03-26 05:30:05,413 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Stopping all currently running jobs of dispatcher akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/dispatcher_1.
2023-03-26 05:30:05,414 INFO  org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy [] - Opening proxy : shky-sc-bigdata-node04:46661
2023-03-26 05:30:05,415 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job DCOL_SSHQ_DEAL_CFETS_RT(774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,418 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Job 774f830cc122ae677f260abe1f050e87 reached terminal state SUSPENDED.
2023-03-26 05:30:05,418 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Shutting down cluster with state SUSPENDED, jobCancelled: false, executionMode: DETACHED
2023-03-26 05:30:05,419 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job DCOL_SSHQ_DEAL_CFETS_RT (774f830cc122ae677f260abe1f050e87) switched from state RUNNING to SUSPENDED.
org.apache.flink.util.FlinkException: Scheduler is being stopped.
	at org.apache.flink.runtime.scheduler.SchedulerBase.closeAsync(SchedulerBase.java:607) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.JobMaster.stopScheduling(JobMaster.java:962) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.JobMaster.stopJobExecution(JobMaster.java:926) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:398) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:214) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:563) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:186) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21) [DCOL-SSHQ-DEAL-RT.jar:?]
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:123) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21) [DCOL-SSHQ-DEAL-RT.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:170) [DCOL-SSHQ-DEAL-RT.jar:?]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:517) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:592) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.actor.ActorCell.invoke(ActorCell.scala:561) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.Mailbox.run(Mailbox.scala:225) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [DCOL-SSHQ-DEAL-RT.jar:?]
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [DCOL-SSHQ-DEAL-RT.jar:?]
2023-03-26 05:30:05,424 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,427 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (1/5) (4d6da1600770b90d8f60defe4d0311ba) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 4d6da1600770b90d8f60defe4d0311ba.
2023-03-26 05:30:05,432 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 4d6da1600770b90d8f60defe4d0311ba.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (2/5) (978fd1b611d73c411d847dffec70d29c) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 978fd1b611d73c411d847dffec70d29c.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 978fd1b611d73c411d847dffec70d29c.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (3/5) (c90825f4e738add5ab63f914f2e6a4ae) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c90825f4e738add5ab63f914f2e6a4ae.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c90825f4e738add5ab63f914f2e6a4ae.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (4/5) (f4d32841b96f5f787d00d231f35273b2) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f4d32841b96f5f787d00d231f35273b2.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f4d32841b96f5f787d00d231f35273b2.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Custom Source -> Filter -> Map -> Filter (5/5) (c1b649d3db941e69e5c2278485ae5272) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c1b649d3db941e69e5c2278485ae5272.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution c1b649d3db941e69e5c2278485ae5272.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,437 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5) (8cf6370b3399f7f43c05f7a877113cdf) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 8cf6370b3399f7f43c05f7a877113cdf.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5) (2115d8c6b643423bd305f5144d07587c) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 2115d8c6b643423bd305f5144d07587c.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5) (007396f72e57ed39c1719cd34b8356fc) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution 007396f72e57ed39c1719cd34b8356fc.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5) (f2dfb07068016004d30684789db0df2a) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution f2dfb07068016004d30684789db0df2a.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5) (db9fbbfeccb06651ea8b1354240a2008) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Discarding the results produced by task execution db9fbbfeccb06651ea8b1354240a2008.
2023-03-26 05:30:05,441 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 774f830cc122ae677f260abe1f050e87.
2023-03-26 05:30:05,441 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2023-03-26 05:30:05,441 INFO  org.apache.flink.runtime.checkpoint.CompletedCheckpoint      [] - Checkpoint with ID 1966 at 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt/774f830cc122ae677f260abe1f050e87/chk-1966' not discarded.
2023-03-26 05:30:05,441 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job 774f830cc122ae677f260abe1f050e87 has been suspended.
2023-03-26 05:30:05,450 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Closing the slot manager.
2023-03-26 05:30:05,450 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Suspending the slot manager.
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [04ab40255d0aba821d9d02ce47254eb3].
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [699c89c4ed3f2849f0818b32e1f9bdc0].
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [93bc4f3c9b477e3134dc0d67859df528].
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [9056be28bacb9f95380bf0b93de5d64d].
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [8025777fbe2631885fb5d9466fd5dfa9].
2023-03-26 05:30:05,461 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection b7d76b9d1d640361b9f02bef96c7de81: Stopping JobMaster for job DCOL_SSHQ_DEAL_CFETS_RT(774f830cc122ae677f260abe1f050e87)..
2023-03-26 05:30:05,463 INFO  org.apache.flink.runtime.dispatcher.MiniDispatcher           [] - Stopped dispatcher akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/dispatcher_1.
2023-03-26 05:30:05,464 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.
2023-03-26 05:30:05,489 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Shutting down remote daemon.
2023-03-26 05:30:05,489 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Shutting down remote daemon.
2023-03-26 05:30:05,491 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remote daemon shut down; proceeding with flushing remote transports.
2023-03-26 05:30:05,491 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remote daemon shut down; proceeding with flushing remote transports.
2023-03-26 05:30:05,542 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remoting shut down.
2023-03-26 05:30:05,542 INFO  akka.remote.RemoteActorRefProvider$RemotingTerminator        [] - Remoting shut down.
2023-03-26 05:30:05,565 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.
2023-03-26 05:30:05,567 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.
End of LogType:jobmanager.logLogType:jobmanager.out
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:0
Log Contents:
End of LogType:jobmanager.outContainer: container_e32_1658913050359_2550751_01_000002 on shky-sc-bigdata-node04_46661
==========================================================================================
LogType:taskmanager.err
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:555
Log Contents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/filecache/13/log4j-slf4j-impl-2.12.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
End of LogType:taskmanager.errLogType:taskmanager.log
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:10880728
Log Contents:
2023-03-24 20:44:32,823 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2023-03-24 20:44:32,828 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Starting YARN TaskExecutor runner (Version: 1.13.3, Scala: 2.11, Rev:a4700e3, Date:2021-10-11T23:52:36+02:00)
2023-03-24 20:44:32,828 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  OS current user: yarn
2023-03-24 20:44:33,187 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Current Hadoop/Kerberos user: yarn
2023-03-24 20:44:33,187 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.241-b07
2023-03-24 20:44:33,187 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Maximum heap size: 1535 MiBytes
2023-03-24 20:44:33,187 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JAVA_HOME: /usr/java/jdk1.8.0_241
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Hadoop version: 2.7.5
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  JVM Options:
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xmx1664299798
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Xms1664299798
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxDirectMemorySize=493921243
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -XX:MaxMetaspaceSize=268435456
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog.file=/vdir/mnt/disk18/hadoop/yarn/logs/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000002/taskmanager.log
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configuration=file:./log4j.properties
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dlog4j.configurationFile=file:./log4j.properties
2023-03-24 20:44:33,189 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Program Arguments:
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.min=359703515b
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.cpu.cores=5.0
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.off-heap.size=0b
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     external-resources=none
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.min=429496736b
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,192 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.off-heap.size=134217728b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.network.max=359703515b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.framework.heap.size=134217728b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.managed.size=1438814063b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.task.heap.size=1530082070b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.numberOfTaskSlots=5
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -D
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     taskmanager.memory.jvm-overhead.max=429496736b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     --configDir
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     .
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.address=shky-sc-bigdata-node04
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.min=201326592b
2023-03-24 20:44:33,193 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dtaskmanager.resource-id=container_e32_1658913050359_2550751_01_000002
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.port=0
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.off-heap.size=134217728b
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dweb.tmpdir=/tmp/flink-web-152c22e1-ebc7-402b-a3c0-34a5b9273d03
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dinternal.taskmanager.resource-id.metadata=shky-sc-bigdata-node04:46661
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.rpc.port=44279
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Drest.address=shky-sc-bigdata-node04
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-metaspace.size=268435456b
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Dsecurity.kerberos.login.keytab=/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000001/krb5.keytab
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.heap.size=469762048b
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -     -Djobmanager.memory.jvm-overhead.max=201326592b
2023-03-24 20:44:33,194 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] -  Classpath: :DCOL-SSHQ-DEAL-RT.jar:lib/flink-connector-debezium-2.1.0.jar:lib/flink-connector-mysql-cdc-2.1.0.jar:lib/flink-csv-1.13.3.jar:lib/flink-json-1.13.3.jar:lib/flink-metrics-prometheus-1.13.3.jar:lib/flink-runtime-web_2.11-1.13.3.jar:lib/flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-table-api-java-1.13.3.jar:lib/flink-table-api-java-bridge_2.11-1.13.3.jar:lib/flink-table-blink_2.11-1.13.3.jar:lib/flink-table-common-1.13.3.jar:lib/flink-table-planner-blink_2.11-1.13.3.jar:lib/flink-table_2.11-1.13.3.jar:lib/hadoop-auth-2.9.2.jar:lib/hadoop-client-2.9.2.jar:lib/hadoop-common-2.9.2.jar:lib/hadoop-hdfs-2.9.2.jar:lib/hudi-flink-bundle_2.11-0.10.0.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-8.0.16.jar:flink-dist_2.11-1.13.3.jar:job.graph:flink-conf.yaml::/etc/yarn1/conf:/usr/lib/hadoop/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/annotations-13.0.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/dnw-1.0.7.jar:/usr/lib/hadoop/lib/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jmxtrans-agent-1.1.1-transwarp.jar:/usr/lib/hadoop/lib/jna-4.2.1.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/netty-all-4.1.5.transwarp.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/sk-0.0.1.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/annotations-13.0.jar:/usr/lib/hadoop-hdfs/lib/apacheds-jdbm1-2.0.0-M2.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/dnw-1.0.7.jar:/usr/lib/hadoop-hdfs/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/hdfs-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop-hdfs/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-api-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-client-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-registry-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/annotations-13.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/avro-1.7.4.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/dom4j-1.6.1.jar:/usr/lib/hadoop-yarn/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/junit-4.11.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/paranamer-2.3.jar:/usr/lib/hadoop-yarn/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2-tests.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/spark-3.1.2-yarn-shuffle.jar:/usr/lib/hadoop-mapreduce/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/activation-1.1.jar:/usr/lib/hadoop-mapreduce/annotations-13.0.jar:/usr/lib/hadoop-mapreduce/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/asm-3.2.jar:/usr/lib/hadoop-mapreduce/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/dnw-1.0.7.jar:/usr/lib/hadoop-mapreduce/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/hadoop-ant-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-archives-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-aws-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-azure-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-datajoin-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-distcp-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-extras-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-gridmix-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-app-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-core-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-openstack-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-rumen-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-sls-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-streaming-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/jettison-1.1.jar:/usr/lib/hadoop-mapreduce/jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/jna-4.2.1.jar:/usr/lib/hadoop-mapreduce/joda-time-2.10.6.jar:/usr/lib/hadoop-mapreduce/jsch-0.1.54.jar:/usr/lib/hadoop-mapreduce/jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/junit-4.11.jar:/usr/lib/hadoop-mapreduce/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-mapreduce/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/sk-0.0.1.jar:/usr/lib/hadoop-mapreduce/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-mapreduce/xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/xz-1.0.jar:/usr/lib/hadoop-mapreduce/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar
2023-03-24 20:44:33,196 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - --------------------------------------------------------------------------------
2023-03-24 20:44:33,197 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2023-03-24 20:44:33,200 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working Directory: /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000002
2023-03-24 20:44:33,215 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.jobgraph-path, job.graph
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.port, 9091
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.interval, 30 SECONDS
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.jobName, flink_reporter_promgateway
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: high-availability.cluster-id, application_1658913050359_2550751
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2023-03-24 20:44:33,216 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.contexts, Client,KafkaClient
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.use-ticket-cache, true
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.class, org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.savepoint.ignore-unclaimed-state, false
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 5
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.randomJobNameSuffix, true
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 5
2023-03-24 20:44:33,217 WARN  org.apache.flink.configuration.GlobalConfiguration           [] - Error while trying to split key and value in configuration file ./flink-conf.yaml:15: "pipeline.classpaths: "
2023-03-24 20:44:33,217 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: yarn.application.name, DCOL_SSHQ_DEAL_CFETS_RT
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 4096mb
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.target, yarn-per-job
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1024mb
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.principal, bigdata_dcm_flink@tdhsh
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.deleteOnShutdown, false
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.attached, false
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: internal.cluster.execution-mode, DETACHED
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: execution.shutdown-on-attached-exit, false
2023-03-24 20:44:33,218 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: pipeline.jars, file:/app/dcol/bigdata_app/cbpc-dcol-sshq-rt/cbpc-dcol-sshq-deal-rt/DCOL-SSHQ-DEAL-RT.jar
2023-03-24 20:44:33,219 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: security.kerberos.login.keytab, /app/dcol/keytabs/flink/bigdata_dcm_flink.keytab
2023-03-24 20:44:33,219 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.promgateway.host, dcol-bigdataservice-node01.cbpc.ccdcpro
2023-03-24 20:44:33,219 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.deployment.config-dir, /app/dcol/flink/conf
2023-03-24 20:44:33,219 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: $internal.yarn.log-config-file, /app/dcol/flink/conf/log4j.properties
2023-03-24 20:44:33,219 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - Current working/local Directory: /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751
2023-03-24 20:44:33,237 INFO  org.apache.flink.runtime.clusterframework.BootstrapTools     [] - Setting directories for temporary files to: /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751,/vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751
2023-03-24 20:44:33,237 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: local keytab path obtained krb5.keytab
2023-03-24 20:44:33,237 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - TM: keytab principal obtained bigdata_dcm_flink@tdhsh
2023-03-24 20:44:33,243 INFO  org.apache.flink.yarn.Utils                                  [] - Resolved keytab path: /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000002/krb5.keytab
2023-03-24 20:44:33,243 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - YARN daemon is running as: yarn Yarn client user obtainer: bigdata_dcm_flink@tdhsh
2023-03-24 20:44:33,695 INFO  org.apache.hadoop.security.UserGroupInformation              [] - Login successful for user bigdata_dcm_flink@tdhsh using keytab file /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000002/krb5.keytab
2023-03-24 20:44:33,698 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Hadoop user set to bigdata_dcm_flink@tdhsh (auth:KERBEROS)
2023-03-24 20:44:33,698 INFO  org.apache.flink.runtime.security.modules.HadoopModule       [] - Kerberos security is enabled and credentials are valid.
2023-03-24 20:44:33,706 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/jaas-4807137155121448347.conf.
2023-03-24 20:44:33,755 WARN  org.apache.flink.configuration.Configuration                 [] - Config uses deprecated configuration key 'web.port' instead of proper key 'rest.port'
2023-03-24 20:44:33,759 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: shky-sc-bigdata-node04.
2023-03-24 20:44:33,764 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address shky-sc-bigdata-node04:0, bind address 0.0.0.0:0.
2023-03-24 20:44:34,212 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-03-24 20:44:34,233 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-03-24 20:44:34,354 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@shky-sc-bigdata-node04:41438]
2023-03-24 20:44:34,512 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@shky-sc-bigdata-node04:41438
2023-03-24 20:44:34,549 WARN  org.apache.flink.runtime.metrics.ReporterSetup               [] - Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for org.apache.flink.metrics.prometheus.PrometheusReporterFactory. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.
2023-03-24 20:44:34,550 WARN  org.apache.flink.runtime.metrics.ReporterSetup               [] - Multiple implementations of the same reporter were found in 'lib' and/or 'plugins' directories for org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory. It is recommended to remove redundant reporter JARs to resolve used versions' ambiguity.
2023-03-24 20:44:34,555 INFO  org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterFactory [] - Configured PrometheusPushGatewayReporter with {host:dcol-bigdataservice-node01.cbpc.ccdcpro, port:9091, jobName:flink_reporter_promgatewayad509daa687147c7836878c19e7fc31c, randomJobNameSuffix:true, deleteOnShutdown:false, groupingKey:{}}
2023-03-24 20:44:34,563 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - Periodically reporting metrics in intervals of 30 s for reporter promgateway of type org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.
2023-03-24 20:44:34,568 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address shky-sc-bigdata-node04:0, bind address 0.0.0.0:0.
2023-03-24 20:44:34,583 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2023-03-24 20:44:34,586 INFO  akka.remote.Remoting                                         [] - Starting remoting
2023-03-24 20:44:34,592 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@shky-sc-bigdata-node04:42846]
2023-03-24 20:44:34,671 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@shky-sc-bigdata-node04:42846
2023-03-24 20:44:34,684 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_container_e32_1658913050359_2550751_01_000002 .
2023-03-24 20:44:34,696 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/blobStore-76b4b60f-0fe6-428c-a75e-5f4197dddaf0
2023-03-24 20:44:34,700 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/blobStore-49f53453-e570-4c01-9084-f49312a88291
2023-03-24 20:44:34,702 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2023-03-24 20:44:34,703 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: container_e32_1658913050359_2550751_01_000002(shky-sc-bigdata-node04:46661)
2023-03-24 20:44:34,736 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1555 GB (69.61% usable)
2023-03-24 20:44:34,736 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1518 GB (67.95% usable)
2023-03-24 20:44:34,737 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1550 GB (69.38% usable)
2023-03-24 20:44:34,737 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1544 GB (69.11% usable)
2023-03-24 20:44:34,737 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1556 GB (69.65% usable)
2023-03-24 20:44:34,737 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1542 GB (69.02% usable)
2023-03-24 20:44:34,737 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1547 GB (69.25% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1555 GB (69.61% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1547 GB (69.25% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1548 GB (69.29% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1513 GB (67.73% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1515 GB (67.82% usable)
2023-03-24 20:44:34,738 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1544 GB (69.11% usable)
2023-03-24 20:44:34,739 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1546 GB (69.20% usable)
2023-03-24 20:44:34,739 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1541 GB (68.98% usable)
2023-03-24 20:44:34,739 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1550 GB (69.38% usable)
2023-03-24 20:44:34,739 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1546 GB (69.20% usable)
2023-03-24 20:44:34,739 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751': total 2234 GB, usable 1538 GB (68.85% usable)
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-3a91f204-bbc3-4a1f-b058-ea5da001e23a for spill files.
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-8a361cd9-c468-4436-9f71-2e15be4b0748 for spill files.
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-83395706-82bf-443d-ab12-ffe1e0f8ad9a for spill files.
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-098abbf6-7561-444f-b707-6186c3a8bbed for spill files.
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-78890026-a38f-4a1f-9dcb-06b14f488a10 for spill files.
2023-03-24 20:44:34,744 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-742e3826-6e3b-45de-9655-8319cb61a12f for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-135cb21c-27a7-461d-8bc2-348a446336ac for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-5c88a1d5-a3a8-4a0a-b051-b57fdf8ebb63 for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-530c4f56-b1be-473f-b3fb-d7367b694082 for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-76d38bce-8853-4cbc-99d2-9e4deeea6b50 for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-58780c0f-caf6-47de-81b4-6779b89201c1 for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-b5c5899d-af7c-4204-add4-35359476666f for spill files.
2023-03-24 20:44:34,745 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-c722f3b1-2433-47af-9781-34f563ef0751 for spill files.
2023-03-24 20:44:34,746 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-61d7e67e-5c04-48cf-9594-0e3cebc2ecc6 for spill files.
2023-03-24 20:44:34,746 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-74b30626-b143-45f5-bb0e-a7c884e24d55 for spill files.
2023-03-24 20:44:34,746 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-eb5df3fa-631f-4bf3-820f-d4d31aac3970 for spill files.
2023-03-24 20:44:34,746 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-feebbb56-a504-4b0a-a946-d5feb6ac8aaf for spill files.
2023-03-24 20:44:34,746 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-30ff5555-5965-470f-90f1-07e6441cf1ba for spill files.
2023-03-24 20:44:34,760 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: /0.0.0.0, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 5 (manual), number of client threads: 5 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2023-03-24 20:44:34,763 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-543d3e74-1b29-415d-97ba-f5f1794d9cc4 for spill files.
2023-03-24 20:44:34,763 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-6a3eb1bc-81bd-4e89-a43f-c2e9946cb246 for spill files.
2023-03-24 20:44:34,763 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-14575e7b-a944-4dc9-a99b-07a24ef93ae5 for spill files.
2023-03-24 20:44:34,763 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-f41cc2e6-f682-4a1f-9866-17ce1da65083 for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-3bbca6d9-d2f6-45ab-9dae-50c9ed26102b for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-81370650-346c-4e85-94ca-396a9ed5e38b for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-2278ba56-b034-4c36-841e-9020518e3b2a for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-98040f2c-75a7-4510-af11-7857840a8c9b for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-219ceea1-92e0-43c9-b46e-c8c9e1356582 for spill files.
2023-03-24 20:44:34,764 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-1400fc00-73ee-4903-a66c-3e642099b851 for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-968f4947-a8ac-4aa8-a759-b0d445f43c8d for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-ffe2bdb5-ae56-4fcd-b654-d1205844c1c4 for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-73c0540e-4e6b-4212-bf0c-43e8906e079d for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-c11aea7b-091a-41a7-bf92-594dee8ab0d6 for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-ebcac157-23f0-4932-8850-42d5ffd17af2 for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-88a5a643-cd28-4db1-bee5-eefed0142bb0 for spill files.
2023-03-24 20:44:34,765 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-e4be3595-931f-45a9-89dd-1d7eab7f1a3e for spill files.
2023-03-24 20:44:34,766 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-9fb4f4ad-41fe-45d9-8ed1-ca395150f97c for spill files.
2023-03-24 20:44:35,171 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 343 MB for network buffer pool (number of memory segments: 10977, bytes per segment: 32768).
2023-03-24 20:44:35,186 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2023-03-24 20:44:35,246 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2023-03-24 20:44:35,248 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 61 ms).
2023-03-24 20:44:35,253 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2023-03-24 20:44:35,289 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 39 ms). Listening on SocketAddress /0:0:0:0:0:0:0:0%0:35157.
2023-03-24 20:44:35,290 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2023-03-24 20:44:35,320 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2023-03-24 20:44:35,335 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2023-03-24 20:44:35,337 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-cfef37ee-c236-494a-b0a2-40a2be9a746c
2023-03-24 20:44:35,337 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-42d32934-70e4-48db-b2c6-cced82a7ec9f
2023-03-24 20:44:35,337 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-38cb1d0b-0937-4039-9cfb-fcc7b2f61458
2023-03-24 20:44:35,337 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-5bbf3397-adf1-42dd-b35c-280c3299127a
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-dc3fc617-1514-4230-b215-22764ad0210b
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-7c4afcdf-bd42-435b-a2bb-87e4b9ed3064
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-aa1aa0ae-31d2-4105-bc87-40d405203bbe
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-5e696b55-d3d6-4f7b-947c-660c56c65b44
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-6a653dbd-ce50-4d0a-adf8-6389572578bf
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-e9438c0c-3f14-41f4-bd3a-7561b8fa87d1
2023-03-24 20:44:35,338 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-6c904998-e6fe-4c6a-8644-5f4be73db182
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-3cecffde-9cfe-4cfc-999f-38b45edda9f7
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-07ab7a24-b9da-4ba9-81da-d44a833e5172
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-98514e53-9c46-4478-80bf-defa790185cb
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-41ab50a4-da7a-4c63-ba13-b0ba3f839fc9
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-ed9e297e-b0de-46dd-8063-42dcf17aee1d
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-574e8cd8-8056-42e2-96a8-02864f2a5cbf
2023-03-24 20:44:35,339 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-fbc3a23e-4829-4306-997b-81ac4571f12c
2023-03-24 20:44:35,341 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2023-03-24 20:44:35,622 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2023-03-24 20:44:35,689 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/resourcemanager_* under registration id 5d02f1104206c3fe6211d60ae91bb4a9.
2023-03-24 20:44:35,706 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 9056be28bacb9f95380bf0b93de5d64d for job 774f830cc122ae677f260abe1f050e87 from resource manager with leader id 00000000000000000000000000000000.
2023-03-24 20:44:35,712 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,713 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 774f830cc122ae677f260abe1f050e87 for job leader monitoring.
2023-03-24 20:44:35,715 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2023-03-24 20:44:35,720 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 699c89c4ed3f2849f0818b32e1f9bdc0 for job 774f830cc122ae677f260abe1f050e87 from resource manager with leader id 00000000000000000000000000000000.
2023-03-24 20:44:35,721 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,722 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 8025777fbe2631885fb5d9466fd5dfa9 for job 774f830cc122ae677f260abe1f050e87 from resource manager with leader id 00000000000000000000000000000000.
2023-03-24 20:44:35,722 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,723 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 04ab40255d0aba821d9d02ce47254eb3 for job 774f830cc122ae677f260abe1f050e87 from resource manager with leader id 00000000000000000000000000000000.
2023-03-24 20:44:35,723 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,724 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 93bc4f3c9b477e3134dc0d67859df528 for job 774f830cc122ae677f260abe1f050e87 from resource manager with leader id 00000000000000000000000000000000.
2023-03-24 20:44:35,724 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,728 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2023-03-24 20:44:35,743 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@shky-sc-bigdata-node04:44279/user/rpc/jobmanager_2 for job 774f830cc122ae677f260abe1f050e87.
2023-03-24 20:44:35,744 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 774f830cc122ae677f260abe1f050e87.
2023-03-24 20:44:35,747 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 774f830cc122ae677f260abe1f050e87.
2023-03-24 20:44:35,772 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,773 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,773 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,773 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,773 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,784 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,821 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba), deploy into slot with allocation id 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,822 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,825 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) [DEPLOYING].
2023-03-24 20:44:35,827 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,841 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf), deploy into slot with allocation id 93bc4f3c9b477e3134dc0d67859df528.
2023-03-24 20:44:35,842 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,842 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) [DEPLOYING].
2023-03-24 20:44:35,843 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,848 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c), deploy into slot with allocation id 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,848 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,848 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) [DEPLOYING].
2023-03-24 20:44:35,850 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,854 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c), deploy into slot with allocation id 9056be28bacb9f95380bf0b93de5d64d.
2023-03-24 20:44:35,854 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,855 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c) [DEPLOYING].
2023-03-24 20:44:35,856 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,860 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae), deploy into slot with allocation id 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,860 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,860 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) [DEPLOYING].
2023-03-24 20:44:35,862 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,865 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc), deploy into slot with allocation id 8025777fbe2631885fb5d9466fd5dfa9.
2023-03-24 20:44:35,866 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,866 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc) [DEPLOYING].
2023-03-24 20:44:35,867 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,871 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2), deploy into slot with allocation id 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,871 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,871 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) [DEPLOYING].
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,871 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,872 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,872 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,873 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,875 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a), deploy into slot with allocation id 04ab40255d0aba821d9d02ce47254eb3.
2023-03-24 20:44:35,876 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,876 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) [DEPLOYING].
2023-03-24 20:44:35,877 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,877 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,877 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,877 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,880 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272), deploy into slot with allocation id 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,881 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,881 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) [DEPLOYING].
2023-03-24 20:44:35,881 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,882 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,882 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,882 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:35,885 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008), deploy into slot with allocation id 699c89c4ed3f2849f0818b32e1f9bdc0.
2023-03-24 20:44:35,885 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) switched from CREATED to DEPLOYING.
2023-03-24 20:44:35,885 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) [DEPLOYING].
2023-03-24 20:44:35,886 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using job/cluster config to configure application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: -1)
2023-03-24 20:44:35,886 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using application-defined state backend: File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480)
2023-03-24 20:44:35,886 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Using legacy state backend File State Backend (checkpoints: 'hdfs://nameservice1:8020/user/bigdata_dcm_flink/ck/sshq/deal_cfetsRt', savepoints: 'null, fileStateThreshold: 20480) as Job checkpoint storage
2023-03-24 20:44:36,019 WARN  org.apache.hadoop.fs.FileSystem                              [] - Cannot load: org.apache.hadoop.fs.sftp.SFTPFileSystem@49abcca8 from /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/filecache/32/hadoop-common-2.9.2.jar
java.lang.UnsupportedOperationException: Not implemented by the SFTPFileSystem FileSystem implementation
	at org.apache.hadoop.fs.FileSystem.getScheme(FileSystem.java:218) ~[flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.fs.FileSystem.loadFileSystems(FileSystem.java:2631) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2648) [flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:2.7.5-10.0]
	at org.apache.flink.runtime.fs.hdfs.HadoopFsFactory.create(HadoopFsFactory.java:98) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(FileSystem.java:526) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.FileSystem.get(FileSystem.java:407) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.core.fs.Path.getFileSystem(Path.java:274) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.state.filesystem.FsCheckpointStorageAccess.<init>(FsCheckpointStorageAccess.java:64) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.state.filesystem.FsStateBackend.createCheckpointStorage(FsStateBackend.java:527) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.<init>(StreamTask.java:341) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.<init>(StreamTask.java:308) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.<init>(SourceStreamTask.java:76) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.<init>(SourceStreamTask.java:72) [DCOL-SSHQ-DEAL-RT.jar:?]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:1.8.0_241]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) [?:1.8.0_241]
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) [?:1.8.0_241]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423) [?:1.8.0_241]
	at org.apache.flink.runtime.taskmanager.Task.loadAndInstantiateInvokable(Task.java:1529) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:730) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-24 20:44:36,381 WARN  org.apache.hadoop.util.NativeCodeLoader                      [] - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-03-24 20:44:36,394 WARN  org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory      [] - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,418 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) switched from DEPLOYING to INITIALIZING.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 1 has no restore state.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 2 has no restore state.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 4 has no restore state.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 3 has no restore state.
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 4/5 - no state to restore
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 5/5 - no state to restore
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 1/5 - no state to restore
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 3/5 - no state to restore
2023-03-24 20:44:36,594 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 2/5 - no state to restore
2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:36,624 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:36,674 INFO  org.apache.kafka.common.security.authenticator.AbstractLogin [] - Successfully logged in.
2023-03-24 20:44:36,676 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT refresh thread started.
2023-03-24 20:44:36,676 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT valid starting at: 2023-03-24T20:44:36.000+0800
2023-03-24 20:44:36,677 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT expires: 2023-03-25T20:44:36.000+0800
2023-03-24 20:44:36,677 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT refresh sleeping until: 2023-03-25T17:01:32.312+0800
2023-03-24 20:44:36,728 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,728 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,728 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2023-03-24 20:44:36,729 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.commit.interval.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,729 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2023-03-24 20:44:36,729 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'session.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,729 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2023-03-24 20:44:36,729 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.commit.interval.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'session.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,730 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2023-03-24 20:44:36,731 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,731 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,732 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2023-03-24 20:44:36,732 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.commit.interval.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,732 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2023-03-24 20:44:36,732 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'session.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,732 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2023-03-24 20:44:36,733 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.commit.interval.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,733 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,733 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2023-03-24 20:44:36,734 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876729
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'session.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.commit.interval.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'session.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,734 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,735 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (5/5) to produce into default topic DCOL_DONE_RES_316
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876734
2023-03-24 20:44:36,735 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (1/5) to produce into default topic DCOL_DONE_RES_316
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,735 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876734
2023-03-24 20:44:36,735 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (4/5) to produce into default topic DCOL_DONE_RES_316
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876732
2023-03-24 20:44:36,736 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (3/5) to produce into default topic DCOL_DONE_RES_316
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,736 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876730
2023-03-24 20:44:36,736 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (2/5) to produce into default topic DCOL_DONE_RES_316
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,760 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876761
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876761
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,761 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876761
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,761 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:36,762 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,762 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876761
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:36,762 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661876762
2023-03-24 20:44:37,096 INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper       [] - Process identifier=hconnection-0x2cb3d2d5 connecting to ZooKeeper ensemble=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:zookeeper.version=3.4.10-39d3a4f269333c922ed3db283be479f9deacaa0f, built on 03/23/2017 10:13 GMT
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:host.name=shky-sc-bigdata-node04
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.version=1.8.0_241
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.vendor=Oracle Corporation
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.home=/usr/java/jdk1.8.0_241/jre
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.class.path=:DCOL-SSHQ-DEAL-RT.jar:lib/flink-connector-debezium-2.1.0.jar:lib/flink-connector-mysql-cdc-2.1.0.jar:lib/flink-csv-1.13.3.jar:lib/flink-json-1.13.3.jar:lib/flink-metrics-prometheus-1.13.3.jar:lib/flink-runtime-web_2.11-1.13.3.jar:lib/flink-shaded-hadoop-2-uber-2.7.5-10.0.jar:lib/flink-shaded-zookeeper-3.4.14.jar:lib/flink-table-api-java-1.13.3.jar:lib/flink-table-api-java-bridge_2.11-1.13.3.jar:lib/flink-table-blink_2.11-1.13.3.jar:lib/flink-table-common-1.13.3.jar:lib/flink-table-planner-blink_2.11-1.13.3.jar:lib/flink-table_2.11-1.13.3.jar:lib/hadoop-auth-2.9.2.jar:lib/hadoop-client-2.9.2.jar:lib/hadoop-common-2.9.2.jar:lib/hadoop-hdfs-2.9.2.jar:lib/hudi-flink-bundle_2.11-0.10.0.jar:lib/log4j-1.2-api-2.12.1.jar:lib/log4j-api-2.12.1.jar:lib/log4j-core-2.12.1.jar:lib/log4j-slf4j-impl-2.12.1.jar:lib/mysql-connector-java-8.0.16.jar:flink-dist_2.11-1.13.3.jar:job.graph:flink-conf.yaml::/etc/yarn1/conf:/usr/lib/hadoop/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/hadoop-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/annotations-13.0.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/avro-1.7.4.jar:/usr/lib/hadoop/lib/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/curator-client-2.7.1.jar:/usr/lib/hadoop/lib/curator-framework-2.7.1.jar:/usr/lib/hadoop/lib/curator-recipes-2.7.1.jar:/usr/lib/hadoop/lib/dnw-1.0.7.jar:/usr/lib/hadoop/lib/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jetty-6.1.26.jar:/usr/lib/hadoop/lib/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop/lib/jmxtrans-agent-1.1.1-transwarp.jar:/usr/lib/hadoop/lib/jna-4.2.1.jar:/usr/lib/hadoop/lib/jsch-0.1.54.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/jsr305-3.0.0.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/netty-all-4.1.5.transwarp.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/sk-0.0.1.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/hadoop-hdfs-nfs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/annotations-13.0.jar:/usr/lib/hadoop-hdfs/lib/apacheds-jdbm1-2.0.0-M2.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/dnw-1.0.7.jar:/usr/lib/hadoop-hdfs/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/hdfs-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-hdfs/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/slf4j-api-1.7.10.jar:/usr/lib/hadoop-hdfs/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/lib/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-api-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-distributedshell-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-client-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-registry-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-applicationhistoryservice-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-nodemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-resourcemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-sharedcachemanager-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/hadoop-yarn-server-web-proxy-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/annotations-13.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/avro-1.7.4.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/dom4j-1.6.1.jar:/usr/lib/hadoop-yarn/lib/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.jar:/usr/lib/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/lib/hadoop-yarn/lib/junit-4.11.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-yarn/lib/paranamer-2.3.jar:/usr/lib/hadoop-yarn/lib/plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-common-guardian-3.1.3.jar:/usr/lib/hadoop-yarn/lib/yarn-plugin-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2-tests.jar:/usr/lib/hadoop-yarn/lib/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-yarn/lib/spark-3.1.2-yarn-shuffle.jar:/usr/lib/hadoop-mapreduce/access-token-filter-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/activation-1.1.jar:/usr/lib/hadoop-mapreduce/annotations-13.0.jar:/usr/lib/hadoop-mapreduce/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/asm-3.2.jar:/usr/lib/hadoop-mapreduce/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/aws-java-sdk-1.7.4.jar:/usr/lib/hadoop-mapreduce/azure-storage-2.0.0.jar:/usr/lib/hadoop-mapreduce/cas-client-core-3.5.1-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/commons-lang3-3.3.2.jar:/usr/lib/hadoop-mapreduce/commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/curator-client-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-framework-2.7.1.jar:/usr/lib/hadoop-mapreduce/curator-recipes-2.7.1.jar:/usr/lib/hadoop-mapreduce/dnw-1.0.7.jar:/usr/lib/hadoop-mapreduce/federation-utils-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/guardian-client-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guardian-common-guardian-3.1.3.jar:/usr/lib/hadoop-mapreduce/guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/hadoop-ant-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-archives-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-auth-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-aws-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-azure-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-datajoin-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-distcp-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-extras-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-gridmix-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-app-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-common-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-core-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-client-shuffle-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-openstack-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-rumen-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-sls-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hadoop-streaming-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/htrace-core-3.1.0-incubating.jar:/usr/lib/hadoop-mapreduce/httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/jackson-jaxrs-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/jackson-xc-1.9.13.jar:/usr/lib/hadoop-mapreduce/java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/jettison-1.1.jar:/usr/lib/hadoop-mapreduce/jetty-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-sslengine-6.1.26.jar:/usr/lib/hadoop-mapreduce/jetty-util-6.1.26.jar:/usr/lib/hadoop-mapreduce/jna-4.2.1.jar:/usr/lib/hadoop-mapreduce/joda-time-2.10.6.jar:/usr/lib/hadoop-mapreduce/jsch-0.1.54.jar:/usr/lib/hadoop-mapreduce/jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/jsr305-3.0.0.jar:/usr/lib/hadoop-mapreduce/junit-4.11.jar:/usr/lib/hadoop-mapreduce/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/mockito-all-1.8.5.jar:/usr/lib/hadoop-mapreduce/netty-all-4.0.23.Final.jar:/usr/lib/hadoop-mapreduce/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/sk-0.0.1.jar:/usr/lib/hadoop-mapreduce/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/swagger-annotations-1.5.9.jar:/usr/lib/hadoop-mapreduce/xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/xz-1.0.jar:/usr/lib/hadoop-mapreduce/zookeeper-3.4.5-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/hadoop-annotations-2.7.2-transwarp-6.2.2.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar
2023-03-24 20:44:37,102 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.io.tmpdir=/tmp
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:java.compiler=<NA>
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:os.name=Linux
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:os.arch=amd64
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:os.version=3.10.0-1062.18.1.el7.x86_64
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:user.name=yarn
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:user.home=/home/yarn
2023-03-24 20:44:37,103 INFO  org.apache.zookeeper.ZooKeeper                               [] - Client environment:user.dir=/vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/container_e32_1658913050359_2550751_01_000002
2023-03-24 20:44:37,104 INFO  org.apache.zookeeper.ZooKeeper                               [] - Initiating client connection, connectString=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181 sessionTimeout=90000 watcher=hconnection-0x2cb3d2d50x0, quorum=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181, baseZNode=/hyperbase1
2023-03-24 20:44:37,126 INFO  org.apache.zookeeper.Login                                   [] - Client successfully logged in.
2023-03-24 20:44:37,127 INFO  org.apache.zookeeper.Login                                   [] - TGT refresh thread started.
2023-03-24 20:44:37,131 INFO  org.apache.zookeeper.client.ZooKeeperSaslClient              [] - Client will use GSSAPI as SASL mechanism.
2023-03-24 20:44:37,131 INFO  org.apache.zookeeper.ClientCnxn                              [] - Opening socket connection to server shky-sc-bigdata-node01/25.11.37.1:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2023-03-24 20:44:37,132 INFO  org.apache.zookeeper.ClientCnxn                              [] - Socket connection established to shky-sc-bigdata-node01/25.11.37.1:2181, initiating session
2023-03-24 20:44:37,132 INFO  org.apache.zookeeper.Login                                   [] - TGT valid starting at:        Fri Mar 24 20:44:37 CST 2023
2023-03-24 20:44:37,132 INFO  org.apache.zookeeper.Login                                   [] - TGT expires:                  Sat Mar 25 20:44:37 CST 2023
2023-03-24 20:44:37,133 INFO  org.apache.zookeeper.Login                                   [] - TGT refresh sleeping until: Sat Mar 25 16:54:32 CST 2023
2023-03-24 20:44:37,136 INFO  org.apache.zookeeper.ClientCnxn                              [] - Session establishment complete on server shky-sc-bigdata-node01/25.11.37.1:2181, sessionid = 0x6f823ee9d45a7ae0, negotiated timeout = 90000
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-4] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-4, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-1, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-2] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-2, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-5] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-5, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-3] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,194 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-3, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,198 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 3 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=0}]
2023-03-24 20:44:37,198 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 1 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=3}]
2023-03-24 20:44:37,198 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=1}]
2023-03-24 20:44:37,198 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 2 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=4}]
2023-03-24 20:44:37,198 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=2}]
2023-03-24 20:44:37,200 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,200 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,200 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,200 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,200 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,205 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=2}=-915623761773}.
2023-03-24 20:44:37,205 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=0}=-915623761773}.
2023-03-24 20:44:37,205 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=1}=-915623761773}.
2023-03-24 20:44:37,205 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=4}=-915623761773}.
2023-03-24 20:44:37,205 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='DCS_NEX_NEWBOND_IBROKER_DEAL', partition=3}=-915623761773}.
2023-03-24 20:44:37,215 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:37,215 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:37,215 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:37,215 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:37,215 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [shky-sc-bigdata-node04:9092, shky-sc-bigdata-node05:9092, shky-sc-bigdata-node10:9092, shky-sc-bigdata-node11:9092, shky-sc-bigdata-node16:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = deal_consumer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = kafka
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = SASL_PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 30000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer2023-03-24 20:44:37,225 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:37,225 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,225 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,225 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:37,225 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:37,226 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661877225
2023-03-24 20:44:37,227 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:37,227 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,227 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,227 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:37,227 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:37,227 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661877227
2023-03-24 20:44:37,230 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:37,230 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,230 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,230 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:37,230 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:37,230 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661877230
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,232 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2023-03-24 20:44:37,232 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,232 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661877232
2023-03-24 20:44:37,232 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2023-03-24 20:44:37,233 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.4.1
2023-03-24 20:44:37,233 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: c57222ae8cd7866b
2023-03-24 20:44:37,233 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1679661877232
2023-03-24 20:44:37,250 INFO  com.cbpc.util.HBaseOperate                                   [] - 获取hbase连接成功 getConn2
2023-03-24 20:44:37,251 INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper       [] - Process identifier=hconnection-0x561fdba3 connecting to ZooKeeper ensemble=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181
2023-03-24 20:44:37,251 INFO  org.apache.zookeeper.ZooKeeper                               [] - Initiating client connection, connectString=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181 sessionTimeout=90000 watcher=hconnection-0x561fdba30x0, quorum=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181, baseZNode=/hyperbase1
2023-03-24 20:44:37,253 INFO  org.apache.zookeeper.client.ZooKeeperSaslClient              [] - Client will use GSSAPI as SASL mechanism.
2023-03-24 20:44:37,253 INFO  org.apache.zookeeper.ClientCnxn                              [] - Opening socket connection to server shky-sc-bigdata-node02/25.11.37.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2023-03-24 20:44:37,254 INFO  org.apache.zookeeper.ClientCnxn                              [] - Socket connection established to shky-sc-bigdata-node02/25.11.37.2:2181, initiating session
2023-03-24 20:44:37,255 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,256 INFO  org.apache.zookeeper.ClientCnxn                              [] - Session establishment complete on server shky-sc-bigdata-node02/25.11.37.2:2181, sessionid = 0x708586578dae7fd0, negotiated timeout = 90000
2023-03-24 20:44:37,265 INFO  com.cbpc.util.HBaseOperate                                   [] - 获取hbase连接成功 getConn2
2023-03-24 20:44:37,265 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-deal_consumer-7, groupId=deal_consumer] Subscribed to partition(s): DCS_NEX_NEWBOND_IBROKER_DEAL-3
2023-03-24 20:44:37,265 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-deal_consumer-6, groupId=deal_consumer] Subscribed to partition(s): DCS_NEX_NEWBOND_IBROKER_DEAL-0
2023-03-24 20:44:37,266 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,266 INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper       [] - Process identifier=hconnection-0xe98b170 connecting to ZooKeeper ensemble=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181
2023-03-24 20:44:37,266 INFO  org.apache.zookeeper.ZooKeeper                               [] - Initiating client connection, connectString=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181 sessionTimeout=90000 watcher=hconnection-0xe98b1700x0, quorum=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181, baseZNode=/hyperbase1
2023-03-24 20:44:37,266 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-deal_consumer-8, groupId=deal_consumer] Subscribed to partition(s): DCS_NEX_NEWBOND_IBROKER_DEAL-2
2023-03-24 20:44:37,266 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-deal_consumer-10, groupId=deal_consumer] Subscribed to partition(s): DCS_NEX_NEWBOND_IBROKER_DEAL-4
2023-03-24 20:44:37,266 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-deal_consumer-9, groupId=deal_consumer] Subscribed to partition(s): DCS_NEX_NEWBOND_IBROKER_DEAL-1
2023-03-24 20:44:37,267 INFO  org.apache.zookeeper.client.ZooKeeperSaslClient              [] - Client will use GSSAPI as SASL mechanism.
2023-03-24 20:44:37,268 INFO  org.apache.zookeeper.ClientCnxn                              [] - Opening socket connection to server shky-sc-bigdata-node01/25.11.37.1:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2023-03-24 20:44:37,268 INFO  org.apache.zookeeper.ClientCnxn                              [] - Socket connection established to shky-sc-bigdata-node01/25.11.37.1:2181, initiating session
2023-03-24 20:44:37,270 INFO  org.apache.zookeeper.ClientCnxn                              [] - Session establishment complete on server shky-sc-bigdata-node01/25.11.37.1:2181, sessionid = 0x6f823ee9d45a7ae1, negotiated timeout = 90000
2023-03-24 20:44:37,274 INFO  com.cbpc.util.HBaseOperate                                   [] - 获取hbase连接成功 getConn2
2023-03-24 20:44:37,275 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,275 INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper       [] - Process identifier=hconnection-0x486c6af6 connecting to ZooKeeper ensemble=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181
2023-03-24 20:44:37,275 INFO  org.apache.zookeeper.ZooKeeper                               [] - Initiating client connection, connectString=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181 sessionTimeout=90000 watcher=hconnection-0x486c6af60x0, quorum=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181, baseZNode=/hyperbase1
2023-03-24 20:44:37,276 INFO  org.apache.zookeeper.client.ZooKeeperSaslClient              [] - Client will use GSSAPI as SASL mechanism.
2023-03-24 20:44:37,279 INFO  org.apache.zookeeper.ClientCnxn                              [] - Opening socket connection to server shky-sc-bigdata-node01/25.11.37.1:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2023-03-24 20:44:37,279 INFO  org.apache.zookeeper.ClientCnxn                              [] - Socket connection established to shky-sc-bigdata-node01/25.11.37.1:2181, initiating session
2023-03-24 20:44:37,281 INFO  org.apache.zookeeper.ClientCnxn                              [] - Session establishment complete on server shky-sc-bigdata-node01/25.11.37.1:2181, sessionid = 0x6f823ee9d45a7ae2, negotiated timeout = 90000
2023-03-24 20:44:37,285 INFO  com.cbpc.util.HBaseOperate                                   [] - 获取hbase连接成功 getConn2
2023-03-24 20:44:37,285 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,285 INFO  org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper       [] - Process identifier=hconnection-0x4850a99a connecting to ZooKeeper ensemble=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181
2023-03-24 20:44:37,285 INFO  org.apache.zookeeper.ZooKeeper                               [] - Initiating client connection, connectString=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181 sessionTimeout=90000 watcher=hconnection-0x4850a99a0x0, quorum=shky-sc-bigdata-node01:2181,shky-sc-bigdata-node02:2181,shky-sc-bigdata-node03:2181, baseZNode=/hyperbase1
2023-03-24 20:44:37,287 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-9, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,287 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-8, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,287 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-7, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,287 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-6, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,287 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-deal_consumer-10, groupId=deal_consumer] Cluster ID: q6LBJEGxQqGE5q1v89RyTg
2023-03-24 20:44:37,288 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-deal_consumer-7, groupId=deal_consumer] Discovered group coordinator shky-sc-bigdata-node04:9092 (id: 2147483643 rack: null)
2023-03-24 20:44:37,288 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-deal_consumer-9, groupId=deal_consumer] Discovered group coordinator shky-sc-bigdata-node04:9092 (id: 2147483643 rack: null)
2023-03-24 20:44:37,288 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-deal_consumer-8, groupId=deal_consumer] Discovered group coordinator shky-sc-bigdata-node04:9092 (id: 2147483643 rack: null)
2023-03-24 20:44:37,288 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-deal_consumer-10, groupId=deal_consumer] Discovered group coordinator shky-sc-bigdata-node04:9092 (id: 2147483643 rack: null)
2023-03-24 20:44:37,288 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-deal_consumer-6, groupId=deal_consumer] Discovered group coordinator shky-sc-bigdata-node04:9092 (id: 2147483643 rack: null)
2023-03-24 20:44:37,302 INFO  org.apache.zookeeper.client.ZooKeeperSaslClient              [] - Client will use GSSAPI as SASL mechanism.
2023-03-24 20:44:37,304 INFO  org.apache.zookeeper.ClientCnxn                              [] - Opening socket connection to server shky-sc-bigdata-node02/25.11.37.2:2181. Will attempt to SASL-authenticate using Login Context section 'Client'
2023-03-24 20:44:37,304 INFO  org.apache.zookeeper.ClientCnxn                              [] - Socket connection established to shky-sc-bigdata-node02/25.11.37.2:2181, initiating session
2023-03-24 20:44:37,306 INFO  org.apache.zookeeper.ClientCnxn                              [] - Session establishment complete on server shky-sc-bigdata-node02/25.11.37.2:2181, sessionid = 0x708586578dae7fd1, negotiated timeout = 90000
2023-03-24 20:44:37,310 INFO  com.cbpc.util.HBaseOperate                                   [] - 获取hbase连接成功 getConn2
2023-03-24 20:44:37,310 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c) switched from INITIALIZING to RUNNING.
2023-03-24 20:44:37,312 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-deal_consumer-8, groupId=deal_consumer] Setting offset for partition DCS_NEX_NEWBOND_IBROKER_DEAL-2 to the committed offset FetchPosition{offset=1802, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=shky-sc-bigdata-node16:9092 (id: 16 rack: null), epoch=-1}}
2023-03-24 20:44:37,312 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-deal_consumer-7, groupId=deal_consumer] Setting offset for partition DCS_NEX_NEWBOND_IBROKER_DEAL-3 to the committed offset FetchPosition{offset=1786, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=shky-sc-bigdata-node17:9092 (id: 17 rack: null), epoch=-1}}
2023-03-24 20:44:37,312 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-deal_consumer-6, groupId=deal_consumer] Setting offset for partition DCS_NEX_NEWBOND_IBROKER_DEAL-0 to the committed offset FetchPosition{offset=1846, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=shky-sc-bigdata-node14:9092 (id: 14 rack: null), epoch=-1}}
2023-03-24 20:44:37,312 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-deal_consumer-10, groupId=deal_consumer] Setting offset for partition DCS_NEX_NEWBOND_IBROKER_DEAL-4 to the committed offset FetchPosition{offset=1891, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=shky-sc-bigdata-node18:9092 (id: 18 rack: null), epoch=-1}}
2023-03-24 20:44:37,312 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-deal_consumer-9, groupId=deal_consumer] Setting offset for partition DCS_NEX_NEWBOND_IBROKER_DEAL-1 to the committed offset FetchPosition{offset=1839, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=shky-sc-bigdata-node15:9092 (id: 15 rack: null), epoch=-1}}	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:698) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-25 04:33:32,683 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:50882] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:33:33,651 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:49584] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:35:26,258 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:38050] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:35:26,260 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:36656] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded2023-03-25 04:38:18,416 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:59208] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-25 04:38:18,417 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:57814] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded2023-03-25 04:38:45,965 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:34512] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-25 04:38:45,967 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:33118] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:242) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.New(HttpClient.java:339) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.New(HttpClient.java:371) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.setNewClient(HttpURLConnection.java:776) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.setNewClient(HttpURLConnection.java:764) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:706) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1591) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
2023-03-25 16:54:32,889 INFO  org.apache.zookeeper.Login                                   [] - Initiating logout for bigdata_dcm_flink@tdhsh
2023-03-25 16:54:32,889 INFO  org.apache.zookeeper.Login                                   [] - Initiating re-login for bigdata_dcm_flink@tdhsh
2023-03-25 16:54:32,898 INFO  org.apache.zookeeper.Login                                   [] - TGT valid starting at:        Sat Mar 25 16:54:32 CST 2023
2023-03-25 16:54:32,898 INFO  org.apache.zookeeper.Login                                   [] - TGT expires:                  Sun Mar 26 16:54:32 CST 2023
2023-03-25 16:54:32,898 INFO  org.apache.zookeeper.Login                                   [] - TGT refresh sleeping until: Sun Mar 26 13:04:28 CST 20232023-03-25 17:01:32,313 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - Initiating logout for bigdata_dcm_flink@tdhsh
2023-03-25 17:01:32,314 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - Initiating re-login for bigdata_dcm_flink@tdhsh
2023-03-25 17:01:32,323 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT valid starting at: 2023-03-25T17:01:32.000+0800
2023-03-25 17:01:32,323 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT expires: 2023-03-26T17:01:32.000+0800
2023-03-25 17:01:32,324 INFO  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT refresh sleeping until: 2023-03-26T12:48:21.577+0800	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[?:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[?:1.8.0_241]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[?:1.8.0_241]
	at java.net.Socket.connect(Socket.java:606) ~[?:1.8.0_241]
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:840) ~[?:1.8.0_241]
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1593) ~[?:1.8.0_241]
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498) ~[?:1.8.0_241]
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[?:1.8.0_241]
	at io.prometheus.client.exporter.PushGateway.doRequest(PushGateway.java:315) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at io.prometheus.client.exporter.PushGateway.push(PushGateway.java:138) ~[flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporter.report(PrometheusPushGatewayReporter.java:63) [flink-metrics-prometheus-1.13.3.jar:1.13.3]
	at org.apache.flink.runtime.metrics.MetricRegistryImpl$ReporterTask.run(MetricRegistryImpl.java:494) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [?:1.8.0_241]
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [?:1.8.0_241]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_241]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]2023-03-26 04:33:12,355 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:33849] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:33:12,857 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:60778] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded2023-03-26 04:34:35,440 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:44724] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:34:35,921 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:43370] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:38:15,696 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:44124] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded
2023-03-26 04:38:16,120 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:42772] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1347375960 - discarded2023-03-26 04:38:51,758 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:48296] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded
2023-03-26 04:38:51,759 WARN  akka.remote.transport.netty.NettyTransport                   [] - Remote connection to [/127.0.0.1:46902] failed with org.apache.flink.shaded.akka.org.jboss.netty.handler.codec.frame.TooLongFrameException: Adjusted frame length exceeds 10485760: 1195725860 - discarded2023-03-26 05:30:05,426 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba).
2023-03-26 05:30:05,426 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,426 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba).
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c).
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,436 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c).
2023-03-26 05:30:05,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae).
2023-03-26 05:30:05,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae).
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2).
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,440 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2).
2023-03-26 05:30:05,441 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272).
2023-03-26 05:30:05,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272).
2023-03-26 05:30:05,443 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf).
2023-03-26 05:30:05,443 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,443 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf).
2023-03-26 05:30:05,444 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c).
2023-03-26 05:30:05,444 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,444 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c).
2023-03-26 05:30:05,445 INFO  org.apache.flink.yarn.YarnTaskExecutorRunner                 [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2023-03-26 05:30:05,446 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc).
2023-03-26 05:30:05,446 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,446 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc).
2023-03-26 05:30:05,446 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,446 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-5] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,447 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,447 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,448 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2023-03-26 05:30:05,448 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2023-03-26 05:30:05,449 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2023-03-26 05:30:05,449 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,449 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a).
2023-03-26 05:30:05,449 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-4] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,449 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,449 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a).
2023-03-26 05:30:05,450 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008).
2023-03-26 05:30:05,450 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) switched from RUNNING to CANCELING.
2023-03-26 05:30:05,450 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008).
2023-03-26 05:30:05,451 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,451 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,453 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,453 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,457 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-543d3e74-1b29-415d-97ba-f5f1794d9cc4
2023-03-26 05:30:05,457 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-cfef37ee-c236-494a-b0a2-40a2be9a746c
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk1/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-3a91f204-bbc3-4a1f-b058-ea5da001e23a
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-6a3eb1bc-81bd-4e89-a43f-c2e9946cb246
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-42d32934-70e4-48db-b2c6-cced82a7ec9f
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk10/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-8a361cd9-c468-4436-9f71-2e15be4b0748
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-38cb1d0b-0937-4039-9cfb-fcc7b2f61458
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-14575e7b-a944-4dc9-a99b-07a24ef93ae5
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk11/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-83395706-82bf-443d-ab12-ffe1e0f8ad9a
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-5bbf3397-adf1-42dd-b35c-280c3299127a
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-f41cc2e6-f682-4a1f-9866-17ce1da65083
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk12/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-098abbf6-7561-444f-b707-6186c3a8bbed
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-dc3fc617-1514-4230-b215-22764ad0210b
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-3bbca6d9-d2f6-45ab-9dae-50c9ed26102b
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-7c4afcdf-bd42-435b-a2bb-87e4b9ed3064
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk13/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-78890026-a38f-4a1f-9dcb-06b14f488a10
2023-03-26 05:30:05,458 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-81370650-346c-4e85-94ca-396a9ed5e38b
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-aa1aa0ae-31d2-4105-bc87-40d405203bbe
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-2278ba56-b034-4c36-841e-9020518e3b2a
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk14/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-742e3826-6e3b-45de-9655-8319cb61a12f
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-5e696b55-d3d6-4f7b-947c-660c56c65b44
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-98040f2c-75a7-4510-af11-7857840a8c9b
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk15/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-135cb21c-27a7-461d-8bc2-348a446336ac
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-6a653dbd-ce50-4d0a-adf8-6389572578bf
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-219ceea1-92e0-43c9-b46e-c8c9e1356582
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk16/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-5c88a1d5-a3a8-4a0a-b051-b57fdf8ebb63
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-e9438c0c-3f14-41f4-bd3a-7561b8fa87d1
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-1400fc00-73ee-4903-a66c-3e642099b851
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk17/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-530c4f56-b1be-473f-b3fb-d7367b694082
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-6c904998-e6fe-4c6a-8644-5f4be73db182
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-968f4947-a8ac-4aa8-a759-b0d445f43c8d
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk2/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-76d38bce-8853-4cbc-99d2-9e4deeea6b50
2023-03-26 05:30:05,459 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-3cecffde-9cfe-4cfc-999f-38b45edda9f7
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-ffe2bdb5-ae56-4fcd-b654-d1205844c1c4
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk3/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-58780c0f-caf6-47de-81b4-6779b89201c1
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-73c0540e-4e6b-4212-bf0c-43e8906e079d
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-07ab7a24-b9da-4ba9-81da-d44a833e5172
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk4/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-b5c5899d-af7c-4204-add4-35359476666f
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-c11aea7b-091a-41a7-bf92-594dee8ab0d6
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-98514e53-9c46-4478-80bf-defa790185cb
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk5/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-c722f3b1-2433-47af-9781-34f563ef0751
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-ebcac157-23f0-4932-8850-42d5ffd17af2
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-41ab50a4-da7a-4c63-ba13-b0ba3f839fc9
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk6/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-61d7e67e-5c04-48cf-9594-0e3cebc2ecc6
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-88a5a643-cd28-4db1-bee5-eefed0142bb0
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-ed9e297e-b0de-46dd-8063-42dcf17aee1d
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk7/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-74b30626-b143-45f5-bb0e-a7c884e24d55
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-e4be3595-931f-45a9-89dd-1d7eab7f1a3e
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-574e8cd8-8056-42e2-96a8-02864f2a5cbf
2023-03-26 05:30:05,460 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk8/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-eb5df3fa-631f-4bf3-820f-d4d31aac3970
2023-03-26 05:30:05,461 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-netty-shuffle-9fb4f4ad-41fe-45d9-8ed1-ca395150f97c
2023-03-26 05:30:05,461 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-dist-cache-fbc3a23e-4829-4306-997b-81ac4571f12c
2023-03-26 05:30:05,461 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk9/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-feebbb56-a504-4b0a-a946-d5feb6ac8aaf
2023-03-26 05:30:05,461 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /vdir/mnt/disk18/hadoop/yarn/local/usercache/bigdata_dcm_flink/appcache/application_1658913050359_2550751/flink-io-30ff5555-5965-470f-90f1-07e6441cf1ba
2023-03-26 05:30:05,464 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:3, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=291.840mb (306016414 bytes), taskOffHeapMemory=0 bytes, managedMemory=274.432mb (287762812 bytes), networkMemory=68.608mb (71940703 bytes)}, allocationId: 04ab40255d0aba821d9d02ce47254eb3, jobId: 774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,465 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2).
2023-03-26 05:30:05,465 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 is already in state CANCELING
2023-03-26 05:30:05,465 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a).
2023-03-26 05:30:05,465 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 is already in state CANCELING
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:1, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=291.840mb (306016414 bytes), taskOffHeapMemory=0 bytes, managedMemory=274.432mb (287762812 bytes), networkMemory=68.608mb (71940703 bytes)}, allocationId: 699c89c4ed3f2849f0818b32e1f9bdc0, jobId: 774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008).
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 is already in state CANCELING
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272).
2023-03-26 05:30:05,467 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 is already in state CANCELING
2023-03-26 05:30:05,467 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,467 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2023-03-26 05:30:05,468 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:4, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=291.840mb (306016414 bytes), taskOffHeapMemory=0 bytes, managedMemory=274.432mb (287762812 bytes), networkMemory=68.608mb (71940703 bytes)}, allocationId: 93bc4f3c9b477e3134dc0d67859df528, jobId: 774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,468 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba).
2023-03-26 05:30:05,468 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 is already in state CANCELING
2023-03-26 05:30:05,468 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf).
2023-03-26 05:30:05,468 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 is already in state CANCELING
2023-03-26 05:30:05,469 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=291.840mb (306016414 bytes), taskOffHeapMemory=0 bytes, managedMemory=274.432mb (287762812 bytes), networkMemory=68.608mb (71940703 bytes)}, allocationId: 9056be28bacb9f95380bf0b93de5d64d, jobId: 774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,469 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c).
2023-03-26 05:30:05,469 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 is already in state CANCELING
2023-03-26 05:30:05,469 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 (2115d8c6b643423bd305f5144d07587c).
2023-03-26 05:30:05,469 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (2/5)#0 is already in state CANCELING
2023-03-26 05:30:05,469 INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation [] - Closing zookeeper sessionid=0x6f823ee9d45a7ae0
2023-03-26 05:30:05,469 INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation [] - Closing zookeeper sessionid=0x6f823ee9d45a7ae1
2023-03-26 05:30:05,470 INFO  org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation [] - Closing zookeeper sessionid=0x708586578dae7fd0
2023-03-26 05:30:05,470 WARN  org.apache.kafka.common.security.kerberos.KerberosLogin      [] - [Principal=bigdata_dcm_flink@tdhsh]: TGT renewal thread has been interrupted and will exit.
2023-03-26 05:30:05,471 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:2, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=291.840mb (306016414 bytes), taskOffHeapMemory=0 bytes, managedMemory=274.432mb (287762812 bytes), networkMemory=68.608mb (71940703 bytes)}, allocationId: 8025777fbe2631885fb5d9466fd5dfa9, jobId: 774f830cc122ae677f260abe1f050e87).
2023-03-26 05:30:05,471 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae).
2023-03-26 05:30:05,471 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 is already in state CANCELING
2023-03-26 05:30:05,471 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to fail task externally async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 (007396f72e57ed39c1719cd34b8356fc).
2023-03-26 05:30:05,471 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Task async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (3/5)#0 is already in state CANCELING
2023-03-26 05:30:05,471 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 0 ms.
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ZooKeeper                               [] - Session: 0x6f823ee9d45a7ae1 closed
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ZooKeeper                               [] - Session: 0x6f823ee9d45a7ae0 closed
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ZooKeeper                               [] - Session: 0x708586578dae7fd0 closed
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ClientCnxn                              [] - EventThread shut down for session: 0x708586578dae7fd0
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ClientCnxn                              [] - EventThread shut down for session: 0x6f823ee9d45a7ae1
2023-03-26 05:30:05,472 INFO  org.apache.zookeeper.ClientCnxn                              [] - EventThread shut down for session: 0x6f823ee9d45a7ae0
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 774f830cc122ae677f260abe1f050e87.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (5/5)#0 (db9fbbfeccb06651ea8b1354240a2008).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (4/5)#0 (f2dfb07068016004d30684789db0df2a).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for async wait operator -> (Sink: Unnamed, Sink: Print to Std. Out) (1/5)#0 (8cf6370b3399f7f43c05f7a877113cdf).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Filter -> Map -> Filter (1/5)#0 (4d6da1600770b90d8f60defe4d0311ba).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Filter -> Map -> Filter (2/5)#0 (978fd1b611d73c411d847dffec70d29c).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2) switched from CANCELING to CANCELED.
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Filter -> Map -> Filter (3/5)#0 (c90825f4e738add5ab63f914f2e6a4ae).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Filter -> Map -> Filter (4/5)#0 (f4d32841b96f5f787d00d231f35273b2).
2023-03-26 05:30:05,473 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Filter -> Map -> Filter (5/5)#0 (c1b649d3db941e69e5c2278485ae5272).
2023-03-26 05:30:05,471 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Error closing producer.
org.apache.kafka.common.errors.InterruptException: java.lang.InterruptedException
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1217) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1176) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.connectors.kafka.internals.FlinkKafkaInternalProducer.close(FlinkKafkaInternalProducer.java:174) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer.close(FlinkKafkaProducer.java:949) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.api.common.functions.util.FunctionUtils.closeFunction(FunctionUtils.java:41) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator.dispose(AbstractUdfStreamOperator.java:117) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.disposeAllOperators(StreamTask.java:864) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runAndSuppressThrowable(StreamTask.java:843) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.cleanUpInvoke(StreamTask.java:756) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runWithCleanUpOnFail(StreamTask.java:662) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:623) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:779) [DCOL-SSHQ-DEAL-RT.jar:?]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:566) [DCOL-SSHQ-DEAL-RT.jar:?]
	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_241]
Caused by: java.lang.InterruptedException
	at java.lang.Object.wait(Native Method) ~[?:1.8.0_241]
	at java.lang.Thread.join(Thread.java:1252) ~[?:1.8.0_241]
	at java.lang.Thread.join(Thread.java:1326) ~[?:1.8.0_241]
	at org.apache.kafka.clients.producer.KafkaProducer.close(KafkaProducer.java:1215) ~[DCOL-SSHQ-DEAL-RT.jar:?]
	... 13 more
End of LogType:taskmanager.logLogType:taskmanager.out
Log Upload Time:Sun Mar 26 05:30:06 +0800 2023
LogLength:2331
Log Contents:
hbaseUtil getConn2
hbaseUtil getConn2
hbaseUtil getConn2
hbaseUtil getConn2
hbaseUtil getConn2
hbaseOperate-init getConn2 链接hbase 成功
hbaseOperate-init getConn2 链接hbase 成功
hbaseOperate-init getConn2 链接hbase 成功
hbaseOperate-init getConn2 链接hbase 成功
hbaseOperate-init getConn2 链接hbase 成功
国际输出结果:2> {"cnrtyAreaChFullID":"CA0000000966","marketGradeName":"","priceSrc":"国际","STATUS_VALUE_ID":"3","indstryCategName":"其他","stlmntSpeedCode":"T+1","num":"","publicFlag":"02","priceSrcId":"01","QUOTEDONE_ID":"7000636929","corpOwnshpTypeID":"079001000000000","processTime":"2023-03-24 23:20:26","resMaturity":"9.5863","assetCrdtRtngSymbol":"","priceDate":"2023-03-24","assetDtlCategID":"B","riseAndFail":"0.05","assetShortName":"22国开20","yield":"3.0495","STATUS_VALUE":"Tkn","corpFullID":"EN0000022430","indstryCategID":"99","entityCrdtRtngAndAssetCrdtRtngSymbol":"--/--","cnrtyAreaChFullName":"北京市","petlFlag":"01","bargainYield":"3.0500","corpFullName":"国家开发银行","guarFlag":"01","entityCrdtRtngSymbol":"","lowest":"","assetDtlCategName":"国开债","QUOTE_STATUS":"否","contnRightFlag":"01","highest":"","cbBdCode":"220220.IB","ltstCupnRate":"2.77","corpOwnshpTypeName":"中央国有","priceTime":"18:24:29","sbdntdFlag":"01"}
国际输出结果:5> {"cnrtyAreaChFullID":"CA0000001834","marketGradeName":"AAA-","priceSrc":"国际","STATUS_VALUE_ID":"2","indstryCategName":"其他","stlmntSpeedCode":"T+0","num":"","publicFlag":"02","priceSrcId":"01","QUOTEDONE_ID":"229020216","corpOwnshpTypeID":"079001000000000","processTime":"2023-03-24 23:20:33","resMaturity":"3.9260/8.9260","assetCrdtRtngSymbol":"AAA","priceDate":"2023-03-24","assetDtlCategID":"G","riseAndFail":"8.08","assetShortName":"22交通银行二级01","yield":"3.4792/3.5746","STATUS_VALUE":"Gvn","corpFullID":"EN0000022457","indstryCategID":"99","entityCrdtRtngAndAssetCrdtRtngSymbol":"AAA/AAA","cnrtyAreaChFullName":"上海市","petlFlag":"01","bargainYield":"3.5600","corpFullName":"交通银行股份有限公司","guarFlag":"01","entityCrdtRtngSymbol":"AAA","lowest":"","assetDtlCategName":"商业银行债","QUOTE_STATUS":"否","contnRightFlag":"02","highest":"","cbBdCode":"2228014.IB","ltstCupnRate":"3.45","corpOwnshpTypeName":"中央国有","priceTime":"18:38:35","sbdntdFlag":"02"}
End of LogType:taskmanager.out
